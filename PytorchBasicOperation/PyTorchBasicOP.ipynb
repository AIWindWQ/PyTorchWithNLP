{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2bb0d4bdcd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.manual_seed(1024)     # 为了保证每次结果运行的稳定，设置随机数种子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在数学上，一个值有以下四种类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scaler:单个数字\n",
    "* Vector:一维数组\n",
    "* Matrix:二维数组\n",
    "* Tensor:高维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先定义一个描述值的函数\n",
    "def describe(x):\n",
    "    print(\"Type: {}\".format(x.type()))\n",
    "    print(\"shape/size: {}\".format(x.shape))\n",
    "    print(\"Values: \\n{}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.Tensor(2, 3))   # 创建一个Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-1.4837,  0.2671, -1.8337],\n",
      "        [-0.1047,  0.6002, -0.5496]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.randn(2, 3))    # 数据服从标准的高斯分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.8793, 0.1163, 0.0540],\n",
      "        [0.5480, 0.2743, 0.7038]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3)    #数据在[0,1]之间，且服从均匀分布\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros(2, 3)\n",
    "describe(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.ones(2, 3)\n",
    "describe(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2, 3).fill_(5)    # \"..._\"带有下划线的函数表示原地操作\n",
    "describe(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch与numpy之间的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npy dtype:float64\n",
      "Type: torch.DoubleTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.3292, 0.8979, 0.7085],\n",
      "        [0.3634, 0.6681, 0.8048]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "npy = np.random.rand(2, 3)\n",
    "print(\"npy dtype:{}\".format(npy.dtype))\n",
    "trh = torch.from_numpy(npy)   # 将numpy转成torch\n",
    "describe(trh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类型以及tensor的一些操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6).view(2, 3)    # view()相当于numpy的reshape\n",
    "describe(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.FloatTensor([[1, 2, 3],\n",
    "                       [4, 5, 6]])   # 创建Float类型的Tensor\n",
    "describe(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "b = b.long()   # 转成Long类型\n",
    "describe(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 2,  4,  6],\n",
      "        [ 8, 10, 12]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.add(b, b)\n",
    "describe(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([3])\n",
      "Values: \n",
      "tensor([5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "# 维度计算\n",
    "b_0 = torch.sum(b, dim=0)\n",
    "describe(b_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([ 6, 15])\n"
     ]
    }
   ],
   "source": [
    "b_1 = torch.sum(b, dim=1)\n",
    "describe(b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "b_T = torch.transpose(b, 0, 1)\n",
    "describe(b_T)\n",
    "# 返回输入b的转置交换维度0和维度1，输入和输出共享内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([1, 2])\n",
      "Values: \n",
      "tensor([[1, 2]])\n"
     ]
    }
   ],
   "source": [
    "# 切片操作\n",
    "describe(b[:1, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([])\n",
      "Values: \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "describe(b[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[1, 3],\n",
      "        [4, 6]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 2])\n",
    "c = torch.index_select(b, dim=1, index=indices)\n",
    "describe(b)\n",
    "describe(c)\n",
    "#index_select(obj, dim, index):obj表示要操作的对象，dim=0表示操作第0轴，\n",
    "#即按行进行索引；dim=1表示按列进行索引；index表示取对应轴上的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Type: torch.LongTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 1])\n",
    "d = torch.index_select(b, dim=0, index=indices)\n",
    "describe(b)\n",
    "describe(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor e dtype:torch.float32\n",
      "ndarray e_np dtype:float32\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor转成np.ndarray\n",
    "e = torch.Tensor([1, 2])\n",
    "e_np = e.numpy()   \n",
    "print(\"tensor e dtype:{}\".format(e.dtype))\n",
    "print(\"ndarray e_np dtype:{}\".format(e_np.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([3, 4])\n",
      "x_add_dim.shape=torch.Size([3, 1, 4])\n",
      "x_reduce_dim.shape=torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# unsequeeze和sequeeze\n",
    "# sequeeze作用是进行维度压缩，去掉维数为1的维度\n",
    "# unsqueeze作用是进行维度扩张，给指定位置加上维数为1的维度\n",
    "x = torch.arange(12).view(3, 4)\n",
    "print(\"x.shape={}\".format(x.shape))\n",
    "\n",
    "x_add_dim = x.unsqueeze(dim=1)  # 在索引为1的位置上，增加维数为1的维度\n",
    "print(\"x_add_dim.shape={}\".format(x_add_dim.shape))\n",
    "\n",
    "x_reduce_dim = x_add_dim.squeeze(dim=1)  # 对增维后的x_add_dim操作，去掉维数\n",
    "                                      #为1的维度(对每一列操作)，因为只有1行\n",
    "print(\"x_reduce_dim.shape={}\".format(x_reduce_dim.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "x.shape=torch.Size([2, 3])\n",
      "x_cat0=tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "x_cat0.shape=torch.Size([4, 3])\n",
      "x_cat1=tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5]])\n",
      "x_cat1.shape=torch.Size([2, 6])\n",
      "x_stack=tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n",
      "x_stack.shape=torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# cat()与stack()\n",
    "x = torch.arange(6).view(2, 3)\n",
    "print(\"x={}\".format(x))\n",
    "print(\"x.shape={}\".format(x.shape))\n",
    "x_cat0 = torch.cat([x, x], dim=0)   # 按行进行拼接\n",
    "print(\"x_cat0={}\".format(x_cat0))\n",
    "print(\"x_cat0.shape={}\".format(x_cat0.shape))\n",
    "x_cat1 = torch.cat([x, x], dim=1)   # 按列进行拼接\n",
    "print(\"x_cat1={}\".format(x_cat1))\n",
    "print(\"x_cat1.shape={}\".format(x_cat1.shape))\n",
    "# cat操作不会改变空间维数，如原始tensor为2维，cat后，仍然是2维\n",
    "x_stack = torch.stack([x, x])  # stack会改变空间的维数\n",
    "print(\"x_stack={}\".format(x_stack))\n",
    "print(\"x_stack.shape={}\".format(x_stack.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代数运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "x.transpose(0, 1):\n",
      " tensor([[ 0,  4,  8],\n",
      "        [ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11]])\n",
      "x.transpose(1, 0):\n",
      " tensor([[ 0,  4,  8],\n",
      "        [ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵转置操作\n",
    "x = torch.arange(0, 12).view(3, 4)\n",
    "print(\"x={}\".format(x))\n",
    "print(\"x.transpose(0, 1):\\n\", x.transpose(0, 1))\n",
    "print(\"x.transpose(1, 0):\\n\", x.transpose(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:\n",
      " torch.Size([3, 4, 5])\n",
      "x:\n",
      " tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9],\n",
      "         [10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [35, 36, 37, 38, 39]],\n",
      "\n",
      "        [[40, 41, 42, 43, 44],\n",
      "         [45, 46, 47, 48, 49],\n",
      "         [50, 51, 52, 53, 54],\n",
      "         [55, 56, 57, 58, 59]]])\n",
      "------------------------\n",
      "x.transpose(1, 0).shape:\n",
      " torch.Size([4, 3, 5])\n",
      "x.transpose(1, 0):\n",
      " tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [20, 21, 22, 23, 24],\n",
      "         [40, 41, 42, 43, 44]],\n",
      "\n",
      "        [[ 5,  6,  7,  8,  9],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [45, 46, 47, 48, 49]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [50, 51, 52, 53, 54]],\n",
      "\n",
      "        [[15, 16, 17, 18, 19],\n",
      "         [35, 36, 37, 38, 39],\n",
      "         [55, 56, 57, 58, 59]]])\n"
     ]
    }
   ],
   "source": [
    "# 在编程的过程中常常需要对数据的shape进行改变\n",
    "batch_size = 3\n",
    "seq_size = 4\n",
    "feature_size = 5\n",
    "\n",
    "x  = torch.arange(batch_size * seq_size * feature_size).view(batch_size,\n",
    "                                                             seq_size,\n",
    "                                                             feature_size)\n",
    "print(\"x.shape:\\n\", x.shape)\n",
    "print(\"x:\\n\", x)\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"x.transpose(1, 0).shape:\\n\", x.transpose(1, 0).shape)\n",
    "print(\"x.transpose(1, 0):\\n\", x.transpose(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: \n",
      " torch.Size([3, 4, 5])\n",
      "x: \n",
      " tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9],\n",
      "         [10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [35, 36, 37, 38, 39]],\n",
      "\n",
      "        [[40, 41, 42, 43, 44],\n",
      "         [45, 46, 47, 48, 49],\n",
      "         [50, 51, 52, 53, 54],\n",
      "         [55, 56, 57, 58, 59]]])\n",
      "---------\n",
      "x.permute(1, 0, 2).shape: \n",
      " torch.Size([4, 3, 5])\n",
      "x.permute(1, 0, 2): \n",
      " tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [20, 21, 22, 23, 24],\n",
      "         [40, 41, 42, 43, 44]],\n",
      "\n",
      "        [[ 5,  6,  7,  8,  9],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [45, 46, 47, 48, 49]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [50, 51, 52, 53, 54]],\n",
      "\n",
      "        [[15, 16, 17, 18, 19],\n",
      "         [35, 36, 37, 38, 39],\n",
      "         [55, 56, 57, 58, 59]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "seq_size = 4\n",
    "feature_size = 5\n",
    "\n",
    "x = torch.arange(batch_size * seq_size * feature_size).view(batch_size, seq_size, feature_size)\n",
    "\n",
    "print(\"x.shape: \\n\", x.shape)\n",
    "print(\"x: \\n\", x)\n",
    "print(\"---------\")\n",
    "#permute用于维度换位\n",
    "print(\"x.permute(1, 0, 2).shape: \\n\", x.permute(1, 0, 2).shape)\n",
    "print(\"x.permute(1, 0, 2): \\n\", x.permute(1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[ 3.,  6.],\n",
      "        [12., 24.]])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵乘法\n",
    "x1 = torch.arange(6).view(2, 3).float()\n",
    "describe(x1)\n",
    "\n",
    "x2 = torch.ones(3, 2)\n",
    "x2[:, 1] += 1\n",
    "describe(x2)\n",
    "\n",
    "describe(torch.mm(x1, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 9.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[2.0 , 3.0]], requires_grad=True)\n",
    "z = 3 * x\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[2., 3.]], requires_grad=True)\n",
      "----------\n",
      "z = 3*x:\n",
      " tensor([[6., 9.]], grad_fn=<MulBackward0>)\n",
      "----------\n",
      "loss = z.sum(): \n",
      " tensor(15., grad_fn=<SumBackward0>)\n",
      "----------\n",
      "after loss.backward(), x.grad:\n",
      " tensor([[3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[2.0, 3.0]], requires_grad=True)\n",
    "print(\"x:\\n\", x)\n",
    "print(\"----------\")\n",
    "z = 3 * x\n",
    "print(\"z = 3*x:\\n\", z)\n",
    "print(\"----------\")\n",
    "loss = z.sum()\n",
    "print(\"loss = z.sum(): \\n\", loss)\n",
    "print(\"----------\")\n",
    "loss.backward()\n",
    "print(\"after loss.backward(), x.grad:\\n\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算条件函数的梯度\n",
    "\n",
    "$$ f(x)=\\left\\{\n",
    "\\begin{array}{ll}\n",
    "       sin(x) \\text{ if } x > 0 \\\\\n",
    "       cos(x) \\text{ otherwise } \\\\\n",
    "\\end{array}\n",
    "\\right.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if(x.data > 0).all():\n",
    "        return torch.sin(x)\n",
    "    else:\n",
    "        return torch.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5403])\n"
     ]
    }
   ],
   "source": [
    "# 对于scaler求梯度\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "y = f(x)\n",
    "y.backward()   # 单个的scaler可以直接求梯度\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5403])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(torch.tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5403, 0.8776])\n"
     ]
    }
   ],
   "source": [
    "# 对于其他类型求梯度\n",
    "x = torch.tensor([1.0, 0.5], requires_grad=True)\n",
    "y = f(x)\n",
    "y.sum().backward()   # 除scaler之外，都需要通过sum()求loss，再进行反向传播\n",
    "                     # 否则，会出错\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    mask = torch.gt(x, 0).float()\n",
    "    return mask * torch.sin(x) + (1 - mask) * torch.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5403, 0.8415])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, -1], requires_grad=True)\n",
    "y = f2(x)\n",
    "y.sum().backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_grad(x):\n",
    "    if x.grad is None:\n",
    "        print(\"没有梯度\")\n",
    "    else:\n",
    "        print(\"gradient: \\n{}\".format(x.grad))\n",
    "        print(\"gradient function:{}\".format(x.grad_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "没有梯度\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "describe(x)\n",
    "describe_grad(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[21., 21.],\n",
      "        [21., 21.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = (x + 2) * (x + 5) + 3\n",
    "describe(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([])\n",
      "Values: \n",
      "21.0\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "describe(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "没有梯度\n"
     ]
    }
   ],
   "source": [
    "describe_grad(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient: \n",
      "tensor([[2.2500, 2.2500],\n",
      "        [2.2500, 2.2500]], grad_fn=<CloneBackward>)\n",
      "gradient function:None\n"
     ]
    }
   ],
   "source": [
    "z.backward(create_graph=True, retain_graph=True)\n",
    "describe_grad(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的过程，$$ y = x^2+7x+13 $$, dy/dx = 2x+7,所以当x=1时，x.grad=9，\n",
    "又因为z.mean()，所以求平均，结果为9/4=2.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 3).to(device)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "shape/size: torch.Size([3, 3])\n",
      "Values: \n",
      "tensor([[0.8004, 0.7361, 0.8983],\n",
      "        [0.3373, 0.3783, 0.7862],\n",
      "        [0.7811, 0.0282, 0.0970]])\n"
     ]
    }
   ],
   "source": [
    "describe(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
